{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from tensorflow import keras\n",
    "import shap\n",
    "\n",
    "from config import DATA_DIR\n",
    "from preprocessing import _downcast_dtypes, _load_userdf\n",
    "from utils import _get_feature\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(\"./generated-datasets/happy/happy_8H_7days_x_train.npy\")\n",
    "y_train = np.load(\"./generated-datasets/happy/happy_8H_7days_y_train.npy\")\n",
    "x_test = np.load(\"./generated-datasets/happy/happy_8H_7days_x_test.npy\")\n",
    "y_test = np.load(\"./generated-datasets/happy/happy_8H_7days_y_test.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading final RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras for model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import GRU\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import LayerNormalization\n",
    "from tensorflow.keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_lstm = keras.models.load_model(\"./model_logs/best_stress_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#happy_lstm = keras.models.load_model(\"./model_logs/best_happy_LSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Shap sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_seq(seq_matrix):\n",
    "    rows = 2\n",
    "    cols = 1\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(9, 9))\n",
    "\n",
    "    shap_matrix = np.mean(seq_matrix, axis=1).reshape((3, 7))\n",
    "    ax[0].imshow(shap_matrix, cmap=plt.cm.get_cmap(\"RdBu\").reversed())\n",
    "    ax[0].set_xticks(np.arange(7))\n",
    "    ax[0].set_xticklabels([\"Mon\", \"Tues\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"])\n",
    "    ax[0].set_yticks(np.arange(3))\n",
    "    ax[0].set_yticklabels([\"0-8\", \"8-16\", \"16-24\"])\n",
    "    \n",
    "    ax[1].plot(np.mean(seq_matrix, axis=1), marker=\"o\")\n",
    "    ax[1].margins(x=0)\n",
    "    ax[1].set_xticks(np.arange(0, 21+1, 3), minor=False)\n",
    "    ax[1].set_xticks(np.arange(0, 21+1, 1), minor=True)\n",
    "    ax[1].set_yticks([-0.002, 0, 0.002], minor=False)\n",
    "\n",
    "    ax[1].grid(axis='both')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(shap_values[0][1], axis=1))\n",
    "plot_seq(shap_values[0][10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Shap values using Gradient Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = stress_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create GradientExplainer from model and training set\n",
    "explainer = shap.GradientExplainer(lstm, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(x_test, nsamples=1000)\n",
    "shap_matrix = shap_values[0]\n",
    "shap_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"./model_logs/best_stress_LSTM/shap_values.npy\", shap_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average SHAP values across 21 sequence periods, then across 1000 samples\n",
    "# results in 37 feature SHAP values from 21000 points\n",
    "shap_per_sample = np.mean(shap_matrix, axis=1)\n",
    "print(\"mean across sequences:\", shap_per_sample.shape)\n",
    "shap_std_per_feature = np.std(shap_per_sample, axis=0)\n",
    "shap_per_feature = np.mean(shap_per_sample, axis=0)\n",
    "print(\"mean across samples:\", shap_per_feature.shape)\n",
    "# plot the variance of shap values\n",
    "#plt.errorbar(range(len(shap_per_feature)), shap_per_feature, yerr=shap_std_per_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SHAP df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_shap = np.load(\"./model_logs/best_stress_LSTM/shap_values.npy\")\n",
    "#happy_shap = np.load(\"./model_logs/best_happy_LSTM/shap_values.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_matrix = stress_shap\n",
    "shap_per_sample = np.mean(shap_matrix, axis=1)\n",
    "feature_per_sample = np.mean(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_per_sample, features=feature_per_sample, feature_names=features_fr, max_display=40, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes the actual value used for the plot\n",
    "shap_mag = np.sum(np.abs(shap_per_sample), axis=0)\n",
    "feature_shap_df = pd.DataFrame(list(zip(features_fr, shap_mag)), columns=[\"feature\", \"shap\"])\n",
    "feature_shap_df = feature_shap_df.set_index(\"feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations with social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_name = {'accel_norm': \"Accéléromètre\",\n",
    " 'accel_low_activity_ratio': \"Accéléromètre - faible activité\",\n",
    " 'accel_high_activity_ratio': \"Accéléromètre - forte activité\",\n",
    " 'accel_total_activity_ratio': \"Accéléromètre - activité totale\",\n",
    " 'app_running_count': \"Apps - nb en cours\",\n",
    " 'battery_temp': \"Batterie - température\",\n",
    " 'battery_volt': \"Batterie - voltage\",\n",
    " 'battery_level': \"Batterie - niveau\",\n",
    " 'battery_is_plugged': \"Batterie - branchée\",\n",
    " 'battery_is_discharging': \"Batterie - décharge\",\n",
    " 'bt_mac_addr_count': \"Bluetooth - nb d'appareils\",\n",
    " 'call_duration': \"Appels - durée\",\n",
    " 'call_phone_hash': \"Appels - nb de contacts\",\n",
    " 'call_type_incoming': \"Appels - nb entrants\",\n",
    " 'call_type_missed': \"Appels - nb manqués\",\n",
    " 'call_type_outgoing': \"Appels - nb sortants\",\n",
    " 'loc_accuracy': \"Lieu - précision\",\n",
    " 'loc_x': \"Lieu - coordonée x\",\n",
    " 'loc_y': \"Lieu - coordonée y\",\n",
    " 'loc_pairwise_dist': \"Lieu - distance parcourue\",\n",
    " 'sms_phone_hash': \"SMS - nb de contacts\",\n",
    " 'sms_type_incoming': \"SMS - nb entrants\",\n",
    " 'sms_type_outgoing': \"SMS - nb sortants\",\n",
    " 'wifi_scan_total': \"Wi-Fi - nb réseaux\",\n",
    " 'wifi_rssi_avg': \"Wi-Fi - signal moyen\",\n",
    " 'wifi_rssi_std': \"Wi-Fi - signal variance\",\n",
    " 'day_of_month': \"Jour du mois\",\n",
    " 'is_weekend': \"Weekend\",\n",
    " 'ema_completion_offset': \"Date d'autoévaluation\",\n",
    " 'ema_completion_hour': \"Heure d'autoévaluation\",\n",
    " 'day_of_week_0.0': \"Lundi\",\n",
    " 'day_of_week_1.0': \"Mardi\",\n",
    " 'day_of_week_2.0': \"Mercredi\",\n",
    " 'day_of_week_3.0': \"Jeudi\",\n",
    " 'day_of_week_4.0': \"Vendred\",\n",
    " 'day_of_week_5.0': \"Samedi\",\n",
    " 'day_of_week_6.0': \"Dimanche\",\n",
    " 'happy': \"Humeur\",\n",
    " 'stress': \"Stress\",\n",
    " 'productive': \"Productivité\",\n",
    " 'eat_healthy': \"Alimentation saine\",\n",
    " 'sleep_h': \"Nb heures sommeil\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df used to extract sequences\n",
    "df = pd.read_csv(\"./generated-datasets/stress/all_users_stress_8H_dl_instances.csv\")\n",
    "# drop rows without label\n",
    "df = df.loc[df[\"happy\"].notna()]\n",
    "# drow unwanted columns\n",
    "features_df = df.drop(columns=[\"Unnamed: 0\", \"userid\", \"timestamp\", \"social_h\", \"stress\", \"happy\", \"productive\", \"eat_healthy\", \"sleep_h\"])\n",
    "# get remaining features name\n",
    "features_eng = features_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = features_df.rename(columns=features_name)\n",
    "features_fr = features_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of correlations\n",
    "social_pearsons = {col:stats.pearsonr(df[\"social_h\"].to_numpy(), features_df[col].to_numpy()) for col in features_fr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df from correlation dictionary and add p-value columns\n",
    "social_df = pd.DataFrame.from_dict(social_pearsons, orient=\"index\", columns=[\"pearson_r\", \"p\"])\n",
    "social_df.index = social_df.index.rename(\"feature\")\n",
    "#social_df[\"p<0.05\"] = np.where(social_df[\"p\"] < 0.05, True, False)\n",
    "#social_df[\"p<0.01\"] = np.where(social_df[\"p\"] < 0.01, True, False)\n",
    "#social_df[\"p<0.001\"] = np.where(social_df[\"p\"] < 0.001, True, False)\n",
    "#social_df[\"p<0.0001\"] = np.where(social_df[\"p\"] < 0.0001, True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Pearson and SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with stats_df\n",
    "stats_df = social_df.merge(feature_shap_df, left_index=True, right_index=True)\n",
    "stats_df = stats_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df[\"shap_rank\"] = stats_df['shap'].abs().rank(method='max')\n",
    "#merged[\"shap_std_rank\"] = merged['shap_std'].abs().rank(method='max')\n",
    "stats_df[\"pearson_mag\"] = stats_df['pearson_r'].abs()\n",
    "stats_df[\"pearson_rank\"] = stats_df['pearson_mag'].abs().rank(method='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kendall Tau statistical test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df.sort_values(by=\"shap\", ascending=False, key=abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kendalltau = stats.kendalltau(stats_df[\"shap_rank\"].to_numpy(), stats_df[\"pearson_rank\"].to_numpy())\n",
    "print(kendalltau)\n",
    "weighted_tau = stats.weightedtau(stats_df[\"shap\"].abs().to_numpy(), stats_df[\"pearson_mag\"].abs().to_numpy(), rank=True, additive=True)\n",
    "print(weighted_tau)\n",
    "\n",
    "# happy\n",
    "# KendalltauResult(correlation=0.04057101069932574, pvalue=0.723968494625439)\n",
    "# WeightedTauResult(correlation=-0.14459490694812802, pvalue=nan)\n",
    "\n",
    "# stress\n",
    "#KendalltauResult(correlation=0.04658153080292956, pvalue=0.6851247178913382)\n",
    "#WeightedTauResult(correlation=-0.05875980292548424, pvalue=nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stress_stats = pd.read_csv(\"./generated-datasets/stress/stats.csv\")\n",
    "happy_stats = pd.read_csv(\"./generated-datasets/happy/stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = happy_stats\n",
    "stats_df = stats_df.rename(columns={\"Unnamed: 0\":\"features\"})\n",
    "stats_df = stats_df.sort_values(by=\"shap\", ascending=False, key=abs)\n",
    "stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = stats_df.sort_values(by=\"shap\", ascending=False, key=abs)\n",
    "top10 = stats_df.iloc[:10].feature\n",
    "top10_val = stats_df.iloc[:10][\"shap\"].abs().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top features\n",
    "plt.rcParams[\"figure.figsize\"] = (4, 10)\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "plt.rcParams[\"legend.loc\"] = \"upper left\"\n",
    "\n",
    "ax = plt.subplot()\n",
    "y = np.arange(10)\n",
    "ax.barh(y, np.flip(top10_val), height=0.7, align='center')\n",
    "ax.set_yticks(y)\n",
    "ax.set_yticklabels(np.flip(top10))\n",
    "ax.set_xticks([0, 1, 2])\n",
    "plt.grid(axis=\"x\")\n",
    "\n",
    "plt.xlabel(\"Valeur de Shapley\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Humeur - Top 10 Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ordered SHAP with pearsons r\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 6)\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "plt.rcParams[\"legend.loc\"] = \"upper left\"\n",
    "\n",
    "# x y data\n",
    "y_shap = stats_df[\"shap\"].to_numpy()\n",
    "y_pearson = stats_df[\"pearson_mag\"].to_numpy()\n",
    "y_pearson_scaled = np.interp(y_pearson,\n",
    "                     (-1, 1),\n",
    "                     (y_shap.min(), y_shap.max())\n",
    "                     )\n",
    "x = np.arange(y_shap.shape[0])\n",
    "\n",
    "# figure\n",
    "fig = plt.figure()\n",
    "# subfigure 1\n",
    "ax1 = plt.subplot(211)\n",
    "color = \"tab:blue\"\n",
    "ax1.set_ylabel(\"Valeur de Shapley\", color=color)\n",
    "ax1.bar(x, y_shap, width=0.8, align='center', color=color, label=\"Shapley value\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=color)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.title(\"Humeur - Importance des features\")\n",
    "\n",
    "#subfigure 2\n",
    "ax2 = plt.subplot(212)\n",
    "color = \"tab:orange\"\n",
    "ax2.set_xlabel(\"Feature #\")\n",
    "ax2.set_ylabel(\"Pearson r\", color=color)\n",
    "ax2.bar(x, y_pearson, width=0.5, align='center', color=color, label=\"Pearson r\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=color)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.title(\"Humeur - Corrélation à l'activité sociale\")\n",
    "#alignYaxes([ax1, ax2], align_values=(0,0))\n",
    "\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignYaxes(axes, align_values=None):\n",
    "    '''Align the ticks of multiple y axes\n",
    "\n",
    "    Args:\n",
    "        axes (list): list of axes objects whose yaxis ticks are to be aligned.\n",
    "    Keyword Args:\n",
    "        align_values (None or list/tuple): if not None, should be a list/tuple\n",
    "            of floats with same length as <axes>. Values in <align_values>\n",
    "            define where the corresponding axes should be aligned up. E.g.\n",
    "            [0, 100, -22.5] means the 0 in axes[0], 100 in axes[1] and -22.5\n",
    "            in axes[2] would be aligned up. If None, align (approximately)\n",
    "            the lowest ticks in all axes.\n",
    "    Returns:\n",
    "        new_ticks (list): a list of new ticks for each axis in <axes>.\n",
    "\n",
    "        A new sets of ticks are computed for each axis in <axes> but with equal\n",
    "        length.\n",
    "    '''\n",
    "    from matplotlib.pyplot import MaxNLocator\n",
    "\n",
    "    nax=len(axes)\n",
    "    ticks=[aii.get_yticks() for aii in axes]\n",
    "    if align_values is None:\n",
    "        aligns=[ticks[ii][0] for ii in range(nax)]\n",
    "    else:\n",
    "        if len(align_values) != nax:\n",
    "            raise Exception(\"Length of <axes> doesn't equal that of <align_values>.\")\n",
    "        aligns=align_values\n",
    "\n",
    "    bounds=[aii.get_ylim() for aii in axes]\n",
    "\n",
    "    # align at some points\n",
    "    ticks_align=[ticks[ii]-aligns[ii] for ii in range(nax)]\n",
    "\n",
    "    # scale the range to 1-100\n",
    "    ranges=[tii[-1]-tii[0] for tii in ticks]\n",
    "    lgs=[-np.log10(rii)+2. for rii in ranges]\n",
    "    igs=[np.floor(ii) for ii in lgs]\n",
    "    log_ticks=[ticks_align[ii]*(10.**igs[ii]) for ii in range(nax)]\n",
    "\n",
    "    # put all axes ticks into a single array, then compute new ticks for all\n",
    "    comb_ticks=np.concatenate(log_ticks)\n",
    "    comb_ticks.sort()\n",
    "    locator=MaxNLocator(nbins='auto', steps=[1, 2, 2.5, 3, 4, 5, 8, 10])\n",
    "    new_ticks=locator.tick_values(comb_ticks[0], comb_ticks[-1])\n",
    "    new_ticks=[new_ticks/10.**igs[ii] for ii in range(nax)]\n",
    "    new_ticks=[new_ticks[ii]+aligns[ii] for ii in range(nax)]\n",
    "\n",
    "    # find the lower bound\n",
    "    idx_l=0\n",
    "    for i in range(len(new_ticks[0])):\n",
    "        if any([new_ticks[jj][i] > bounds[jj][0] for jj in range(nax)]):\n",
    "            idx_l=i-1\n",
    "            break\n",
    "\n",
    "    # find the upper bound\n",
    "    idx_r=0\n",
    "    for i in range(len(new_ticks[0])):\n",
    "        if all([new_ticks[jj][i] > bounds[jj][1] for jj in range(nax)]):\n",
    "            idx_r=i\n",
    "            break\n",
    "\n",
    "    # trim tick lists by bounds\n",
    "    new_ticks=[tii[idx_l:idx_r+1] for tii in new_ticks]\n",
    "\n",
    "    # set ticks for each axis\n",
    "    for axii, tii in zip(axes, new_ticks):\n",
    "        axii.set_yticks(tii)\n",
    "\n",
    "    return new_ticks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Stress and Mood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_stats = pd.read_csv(\"./generated-datasets/stress/stats.csv\")\n",
    "happy_stats = pd.read_csv(\"./generated-datasets/happy/stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_stats = stress_stats.merge(happy_stats, left_on=\"pearson_rank\", right_on=\"pearson_rank\")\n",
    "labels_stats = labels_stats.sort_values(\"shap_x\", ascending=False, key=abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kendalltau = stats.kendalltau(labels_stats[\"shap_rank_x\"].to_numpy(), labels_stats[\"shap_rank_y\"].to_numpy())\n",
    "print(kendalltau)\n",
    "weighted_tau = stats.weightedtau(labels_stats[\"shap_rank_x\"].abs().to_numpy(), labels_stats[\"shap_rank_y\"].abs().to_numpy(), rank=True, additive=True)\n",
    "print(weighted_tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ordered SHAP with pearsons r\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 6)\n",
    "\n",
    "y_stress = labels_stats[\"shap_x\"].to_numpy()\n",
    "y_happy = labels_stats[\"shap_y\"].to_numpy()\n",
    "\n",
    "\n",
    "x = np.arange(y_stress.shape[0])\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = plt.subplot(211)\n",
    "\n",
    "color = \"tab:blue\"\n",
    "ax1.set_ylabel(\"Stress\", color=color)\n",
    "ax1.bar(x, y_stress, width=0.8, align='center', color=color, label=\"Shapley value\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=color)\n",
    "\n",
    "ax2 = plt.subplot(212)\n",
    "\n",
    "ax2.set_xlabel(\"Feature #\")\n",
    "ax2.set_ylabel(\"Humeur\", color=color)\n",
    "ax2.bar(x, y_happy, width=0.8, align='center', color=color, label=\"Pearson r\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=color)\n",
    "\n",
    "#alignYaxes([ax1, ax2], align_values=(0,0))\n",
    "\n",
    "ax.legend()\n",
    "plt.title(\"Stress - Feature importance\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de1e15777db83a4a38311ecc646d02ddde9c0d3bc45a52b7bb762b687e5b017a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
